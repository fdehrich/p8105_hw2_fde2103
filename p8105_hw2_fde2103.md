Homework 2
================
Fiona Ehrich

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trash Wheel dataset.

``` r
trashwheel_df =
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation dataframes. The technique being used
(creating a “helper” tibble) was presented by Jeff during the live
session.

``` r
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df =
  bind_rows(precip_2018, precip_2017)

precip_df =
  left_join(precip_df, month_df, by = "month") %>% 
  select(year, month_name, total, -month) # Reordering the variables to be in a more useful order and getting rid of the old month variable
```

**Mr. Trash Wheel data** (`trashwheel_df`)

This dataset contains information from the Mr. Trash Wheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trash wheel collects that trash, and stores it in a dumpster. The
dataset contains information on year, month, and trash collected,
including some specific kinds of trash. There are a total of 344 rows in
our final dataset.

The median number of sports balls found in a dumpster in 2017 was 8.

**Preciptation data** (`precip_df`)

This dataset contains the total preceiptation per month for 2017 and
2018. There are a total of 24 rows in our final dataset.

The total precipitation in 2018 was 70.33 inches.

## Problem 2

Read and clean the NYC Transit data (including converting the entry
variable from character to logical).

``` r
transit_df =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>%
  select( # Selecting the desired variables
    line,
    station_name,
    station_latitude,
    station_longitude,
    route1:route11,
    entry,
    vending,
    entrance_type,
    ada
    ) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) # Converting the entry variable from character to logical
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This dataset provides various types of information regarding NYC subway
stations and their entrances/exits. The variables in the dataset are:
line, station name, station latitude, station longitude, its routes 1
through 11 (each route captured as its own variable), whether or not
there is entry, entrance type, and whether or not it is ADA compliant.
So far, I have read the dataset, reformatted the names using
`janitor::clean_names()`, selected the variables that I would like to
keep, and converted the `entry` variable from character to logical.
There are 1868 rows and 19 columns in the dataset. These data could be
tidier. In particular, the route information is displayed in a “wide”
fashion and could be combined into two variables (one that expresses
route number and one that expresses route name).

There are 356 distinct stations.

73 stations are ADA compliant.
